<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Monzer Alatrach" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         May 9, 2021 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<pre class="r"><code>class_diag &lt;- function(probs,truth){ 
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV 
  if(is.character(truth)==TRUE) truth&lt;-as.factor(truth) 
  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1 
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),factor(truth, levels=c(0,1))) 
  acc=sum(diag(tab))/sum(tab) 
  sens=tab[2,2]/colSums(tab)[2] 
  spec=tab[1,1]/colSums(tab)[1] 
  ppv=tab[2,2]/rowSums(tab)[2] 
  
#CALCULATE EXACT AUC 
  ord&lt;-order(probs, decreasing=TRUE) 
  probs &lt;- probs[ord]; truth &lt;- truth[ord] 
  TPR=cumsum(truth)/max(1,sum(truth))  
  FPR=cumsum(!truth)/max(1,sum(!truth)) 
  dup &lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE) 
  TPR &lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1) 
  n &lt;- length(TPR) 
  auc &lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n])) 
  data.frame(acc,sens,spec,ppv,auc) 
}</code></pre>
<pre class="r"><code>library(tidyverse)
library(cluster)

NBA &lt;- read_csv(&quot;NBA Advanced.csv&quot;)

NBA &lt;- NBA %&gt;% pivot_wider(1, names_from=`Player,Pos,PER,WS,BPM,VORP` , values_from = `Player,Pos,PER,WS,BPM,VORP`) %&gt;% pivot_longer(contains(&quot;,&quot;)) %&gt;% separate(name, into = c(&quot;Player&quot;, &quot;Pos&quot; , &quot;PER&quot; , &quot;WS&quot;, &quot;BPM&quot; , &quot;VORP&quot;), sep = &quot;,&quot;, convert = T) %&gt;% separate(&quot;Player&quot; , into = c(&quot;Player&quot; , &quot;ID&quot;), sep = &quot;\\\\&quot;) %&gt;% na.omit() %&gt;% select(c(&quot;Player&quot;, &quot;Pos&quot; , &quot;PER&quot; , &quot;WS&quot;, &quot;BPM&quot; , &quot;VORP&quot;)) </code></pre>
<p>In this Dataset I am calling it NBA theree are 6 total variables. The dataset is the advanced statistics of all the NBA players that have played in the 2020-2021 regular season. The variables in the set are the Player name, the Position the player plays (C, PF, SF, SG, or PG), the PER which is the players efficiency rating on offense, the WS which is the win shares that are attributed to a player based on their pereformance, the BPM which is the players Box-Plus-Minus or a stat that tracks how many points a player has added throughout the season, and the VORP which is the value over replacement for each player. I tidyâ€™d up the data. There are a total of 509 players in the set.</p>
<pre class="r"><code>library(dplyr)
library(rstatix)
library(mvtnorm)
library(ggExtra)

ggplot(NBA, aes(x = PER, y = WS)) +
geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~Pos)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>group &lt;- NBA$Pos
DVs &lt;- NBA %&gt;% select(PER, WS) 
sapply(split(DVs,group), mshapiro_test)</code></pre>
<pre><code>## C PF PG SF SG
## statistic 0.547146 0.8451763 0.8201294 0.9727513
0.9050628
## p.value 1.80004e-15 2.313532e-09 9.449686e-10 0.06296138
4.328859e-07</code></pre>
<pre class="r"><code>man1&lt;-manova(cbind(PER,WS)~Pos, data=NBA)
summary(man1)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## Pos 4 0.064731 4.2145 8 1008 5.523e-05 ***
## Residuals 504
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>## Response PER :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Pos 4 1327.7 331.92 7.3595 9.136e-06 ***
## Residuals 504 22731.1 45.10
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response WS :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Pos 4 109.43 27.3587 6.0324 9.533e-05 ***
## Residuals 504 2285.77 4.5353
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>NBA%&gt;%group_by(Pos)%&gt;%summarize(mean(PER),mean(WS))</code></pre>
<pre><code>## # A tibble: 5 x 3
##   Pos   `mean(PER)` `mean(WS)`
##   &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;
## 1 C            15.8       2.80
## 2 PF           12.5       1.72
## 3 PG           13.1       1.98
## 4 SF           11.7       1.80
## 5 SG           11.0       1.40</code></pre>
<pre class="r"><code>pairwise.t.test(NBA$PER, NBA$Pos, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  NBA$PER and NBA$Pos 
## 
##    C       PF      PG      SF     
## PF 0.00055 -       -       -      
## PG 0.00518 0.53070 -       -      
## SF 6.3e-05 0.43498 0.17524 -      
## SG 3.8e-07 0.09189 0.02250 0.42959
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(NBA$WS, NBA$Pos, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  NBA$WS and NBA$Pos 
## 
##    C       PF      PG      SF     
## PF 0.00038 -       -       -      
## PG 0.00796 0.37907 -       -      
## SF 0.00189 0.78946 0.57069 -      
## SG 2.8e-06 0.24978 0.04375 0.17701
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>0.05/23</code></pre>
<pre><code>## [1] 0.002173913</code></pre>
<p>Pos is the independent variable and PER and WS are the dependent variables. I performed 1 MANOVA, 2 ANOVA, and 20 t-tests. The probability of at least one type1 error is 0.00217. I did post-hoc ANOVA and pair-wise t-tests. The overall MANOVA is significant. The assumptions for a MANOVA are random and independent observations, multivariate dependent varibales, homogeneity, a linear relatioship between DVs, no extreme ouliers, and no multicollinearity. By using the Shapiro-wilkes test normality was not met for all of the Pos as SF was the only non-significant value. I do not belive that my data met all of the assumptions</p>
<pre class="r"><code>NBA1 &lt;- NBA %&gt;% mutate(Pos=ifelse(Pos==&quot;C&quot;,1,0))
NBA1%&gt;%group_by(Pos)%&gt;%
  summarize(means=mean(WS))%&gt;%summarize(`mean_diff`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1      1.09</code></pre>
<pre class="r"><code>rand_dist&lt;-vector() 

for(i in 1:5000){
new&lt;-data.frame(WS=sample(NBA1$WS),condition=NBA1$Pos) 
rand_dist[i]&lt;-mean(new[new$condition==1,]$WS)-   
              mean(new[new$condition==0,]$WS)} 
{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-1.086, 1.086),col=&quot;red&quot;)}</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(rand_dist)</code></pre>
<pre><code>## [1] 0.001372163</code></pre>
<pre class="r"><code>mean(rand_dist&gt;1.086 | rand_dist&lt; -1.086)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>t.test(data=NBA1,WS~Pos,)</code></pre>
<pre><code>##
## Welch Two Sample t-test
##
## data: WS by Pos
## t = -3.6875, df = 115.69, p-value = 0.0003464
## alternative hypothesis: true difference in means is not
equal to 0
## 95 percent confidence interval:
## -1.6698283 -0.5028195
## sample estimates:
## mean in group 0 mean in group 1
## 1.709375 2.795699</code></pre>
<p>I performed a randomization test for the mean difference for my data. I used the WS as my dependent variable and Pos as the independent variable. I first made the Pos data easier to understand by making all players that are Centers a 1 and all others a 0. The null hypothesis is that the mean WS is the same for Centers and all other positions. The alternate hypothesis is that mean WS is different for Centers and all other positions. The mean difference for the unscrambled data I got is 1.086. I then ran 5000 times and got a mean difference of 0 which is way lower. The p-value for the permutation test I got was 0 which is less than 0.05 so the null hypothesis is rejected. When running a t-test, the same conclusion is seen as the p-value of 0 is less than 0.05 so the null is rejected. So, there is a difference in the mean WS for centers and all other positions.</p>
<pre class="r"><code>library(sandwich)
library(lmtest)
x&lt;- scale(NBA1$PER)
y &lt;- scale(NBA1$WS)
fit&lt;-lm(Pos~x, data= NBA1)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = Pos ~ x, data = NBA1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -0.37706 -0.20014 -0.16476 -0.09282 1.44618
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.18271 0.01678 10.889 &lt; 2e-16 ***
## x 0.08117 0.01680 4.832 1.79e-06 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.3786 on 507 degrees of
freedom
## Multiple R-squared: 0.04403, Adjusted R-squared: 0.04214
## F-statistic: 23.35 on 1 and 507 DF, p-value: 1.791e-06</code></pre>
<pre class="r"><code>fit1&lt;-lm(Pos~y, data=NBA1)
summary(fit1)</code></pre>
<pre><code>##
## Call:
## lm(formula = Pos ~ y, data = NBA1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -0.4375 -0.1962 -0.1376 -0.1135 0.8900
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.18271 0.01684 10.851 &lt; 2e-16 ***
## y 0.07485 0.01685 4.441 1.1e-05 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.3799 on 507 degrees of
freedom
## Multiple R-squared: 0.03745, Adjusted R-squared: 0.03555
## F-statistic: 19.73 on 1 and 507 DF, p-value: 1.099e-05</code></pre>
<pre class="r"><code>fit2&lt;-lm(Pos~y + x, data=NBA1)
summary(fit2)</code></pre>
<pre><code>##
## Call:
## lm(formula = Pos ~ y + x, data = NBA1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -0.45165 -0.19584 -0.14949 -0.08013 1.29145
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.18271 0.01674 10.91 &lt; 2e-16 ***
## y 0.03978 0.02139 1.86 0.06346 .
## x 0.05645 0.02139 2.64 0.00856 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.3777 on 506 degrees of
freedom
## Multiple R-squared: 0.05052, Adjusted R-squared: 0.04677
## F-statistic: 13.46 on 2 and 506 DF, p-value: 2.012e-06</code></pre>
<pre class="r"><code>ggplot(NBA1, aes(x=WS, y=PER,group=Pos))+geom_point(aes(color=Pos))+
geom_smooth(method=&quot;lm&quot;,se=F,fullrange=T,aes(color=Pos))+
theme(legend.position=c(.9,.19))+xlab(&quot;&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>resids&lt;-fit2$residuals
fitvals&lt;-fit2$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>resids&lt;- lm(y~x, data=NBA1)$residuals
resids &lt;-fit2$residuals
ks.test(resids, &quot;pnorm&quot;, mean=0, sd(resids)) </code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  resids
## D = 0.34752, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>fit3&lt;-lm(Pos~WS+PER,data=NBA1) 
bptest(fit2)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit2
## BP = 11.416, df = 2, p-value = 0.003319</code></pre>
<pre class="r"><code>summary(fit3)$coef</code></pre>
<pre><code>##                Estimate  Std. Error  t value    Pr(&gt;|t|)
## (Intercept) 0.043407823 0.035679496 1.216604 0.224322038
## WS          0.018319175 0.009848652 1.860069 0.063455737
## PER         0.008202558 0.003107505 2.639596 0.008556624</code></pre>
<pre class="r"><code>coeftest(fit2, vcov = vcovHC(fit3))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.182711 0.071648 2.5501 0.01106 *
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>I first ran a linear regression for Pos and PER. I scaled the PER data first. For the estimate I got a value of 0.081 which means that 0.081 is the average increase in Pos for every 1 increase in PER and I got a value of 0.18 for the intercept which means at 0 PER the Pos is 0.18. I then did a linear regression for WS and Pos and scaled WS first. I got an estimate value of 0.075 which means that the 0.075 is the average increase in Pos for every 1 increase in WS and I got a value of 0.18 for the intercept which means at 0 WS the Pos is 0.18. I then did a mutliple regression for Pos and the interaction between PER and WS. I got an estimate value of 0.039 for PER and 0.056 for WS. This means that with holding PER constant, 0.056 is the average increase in Pos for every 1 incrrease in WS and with holding WS constnat, 0.039 is the average increase in Pos for every 1 increase in PER. The intercept for the interaction is 0.18 which means with PER and WS both at 0 the Pos is 0.18. The proportion of the variance that can be explained by the model is 0.047 or 4.7%. In order to test forr assumptions I used the KS test. I got a p-value of less than 0.05 which means we reject the null which is the distribution is normal so mine is not normal. I then did a bp test to test for homoskedacity and I got a p-value of less than 0.05 which means we reject the null which is homoskedacity. Meaning the data is heteroskedacity. I also did a test for linearity for the data by using a graph and it is clear the data is not linear either since there is no constant variance. I then recomputed the regression results with robust standard errors. The standard errors increased after recomputing. This means that the p-values increased to all above 0.05 so no significance any longer for PER while WS was not-significant before and after the rercomputing.</p>
<pre class="r"><code>fit&lt;-lm(Pos ~ PER + WS, data=NBA1)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = Pos ~ PER + WS, data = NBA1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -0.45165 -0.19584 -0.14949 -0.08013 1.29145
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.043408 0.035679 1.217 0.22432
## PER 0.008203 0.003108 2.640 0.00856 **
## WS 0.018319 0.009849 1.860 0.06346 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.3777 on 506 degrees of
freedom
## Multiple R-squared: 0.05052, Adjusted R-squared: 0.04677
## F-statistic: 13.46 on 2 and 506 DF, p-value: 2.012e-06</code></pre>
<pre class="r"><code>boot_dat&lt;- sample_frac(NBA1, replace=T)
samp_distn&lt;-replicate(5000, {
boot_dat &lt;- sample_frac(NBA1, replace=T) 
fit1 &lt;- lm(Pos~PER+WS, data=boot_dat) 
coef(fit1) 
})

samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)         PER         WS
## 1  0.06381497 0.006436484 0.01468606</code></pre>
<pre class="r"><code>samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% pivot_longer(1:3) %&gt;% group_by(name) %&gt;%
summarize(lower=quantile(value,.025), upper=quantile(value,.975))</code></pre>
<pre><code>## # A tibble: 3 x 3
##   name           lower  upper
##   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;
## 1 (Intercept) -0.108   0.140 
## 2 PER         -0.00144 0.0235
## 3 WS          -0.0139  0.0440</code></pre>
<p>I then ran the regression model with the interaction of PER and WS but I this time computed the bootstrapped standard errors. I did this by resampling observations which I resampled 5000 times. The standard errors for the bootrapped data were higher for both PER and WS compared to the normal SE but when compared to the robust SE the bootstrapped SE are smaller for both PER and WS. This means the p-value for the bootstrapp is more than the normal SE but smaller than the robust SE.</p>
<pre class="r"><code>library(plotROC)
NBA2 &lt;- NBA %&gt;% mutate(Pos=ifelse(Pos == &quot;C&quot;, &quot;C&quot;, &quot;A&quot;))
NBA2 &lt;- NBA2 %&gt;% mutate(y=ifelse(Pos==&quot;C&quot;,1,0))
NBA2</code></pre>
<pre><code>## # A tibble: 509 x 7
## Player Pos PER WS BPM VORP y
## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Precious Achiuwa A 13.9 1.2 -4.3 -0.4 0
## 2 Jaylen Adams A -6.5 -0.1 -19.8 -0.1 0
## 3 Steven Adams C 15.2 4 -0.8 0.5 1
## 4 Bam Adebayo C 22.9 8.1 4.8 3.4 1
## 5 LaMarcus Aldridge C 15.7 1.2 -0.6 0.2 1
## 6 Ty-Shon Alexander A -0.3 -0.1 -11 -0.1 0
## 7 Nickeil Alexander-Walker A 12.4 0.7 -1.7 0.1 0
## 8 Grayson Allen A 12.8 2.6 -0.5 0.5 0
## 9 Jarrett Allen C 21 6.2 1.5 1.5 1
## 10 Al-Farouq Aminu A 8.9 0.1 -4 -0.2 0
## # â€¦ with 499 more rows</code></pre>
<pre class="r"><code>fit&lt;-glm(y~PER + WS,data=NBA2,family=binomial(link=&quot;logit&quot;))
coeftest(fit)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -2.915488 0.371033 -7.8578 3.91e-15 ***
## PER 0.095169 0.029852 3.1880 0.001433 **
## WS 0.039032 0.067729 0.5763 0.564414
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit))</code></pre>
<pre><code>## (Intercept)         PER          WS 
##  0.05417757  1.09984423  1.03980352</code></pre>
<pre class="r"><code>NBA2$prob &lt;- predict(fit,type=&quot;response&quot;)
NBA2$predicted &lt;- ifelse(NBA2$prob&gt;.5,&quot;C&quot;,&quot;A&quot;)
NBA2</code></pre>
<pre><code>## # A tibble: 509 x 9
## Player Pos PER WS BPM VORP y prob predicted
## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
## 1 Precious Achiuwa A 13.9 1.2 -4.3 -0.4 0 0.176 A
## 2 Jaylen Adams A -6.5 -0.1 -19.8 -0.1 0 0.0283 A
## 3 Steven Adams C 15.2 4 -0.8 0.5 1 0.212 A
## 4 Bam Adebayo C 22.9 8.1 4.8 3.4 1 0.397 A
## 5 LaMarcus Aldridge C 15.7 1.2 -0.6 0.2 1 0.202 A
## 6 Ty-Shon Alexander A -0.3 -0.1 -11 -0.1 0 0.0498 A
## 7 Nickeil Alexander-Walker A 12.4 0.7 -1.7 0.1 0 0.153 A
## 8 Grayson Allen A 12.8 2.6 -0.5 0.5 0 0.169 A
## 9 Jarrett Allen C 21 6.2 1.5 1.5 1 0.337 A
## 10 Al-Farouq Aminu A 8.9 0.1 -4 -0.2 0 0.113 A
## # â€¦ with 499 more rows</code></pre>
<pre class="r"><code>NBA2$logit&lt;-predict(fit)
NBA2$Pos&lt;-factor(NBA2$Pos,levels=c(&quot;C&quot;,&quot;A&quot;))
table(truth=NBA2$Pos, prediction=NBA2$predicted)%&gt;%addmargins</code></pre>
<pre><code>##      prediction
## truth   A   C Sum
##   C    91   2  93
##   A   414   2 416
##   Sum 505   4 509</code></pre>
<pre class="r"><code>Accuracy &lt;- (2+414)/509 #Accuracy
TNR &lt;- (414/416) #TNR
TPR &lt;- (2/93) #TPR
PPV &lt;- (2/4) #PPV
Accuracy</code></pre>
<pre><code>## [1] 0.8172888</code></pre>
<pre class="r"><code>TNR</code></pre>
<pre><code>## [1] 0.9951923</code></pre>
<pre class="r"><code>TPR</code></pre>
<pre><code>## [1] 0.02150538</code></pre>
<pre class="r"><code>PPV</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="r"><code>ggplot(NBA2,aes(logit, fill=Pos))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ROCplot&lt;-ggplot(NBA2)+geom_roc(aes(d=Pos,m=prob), n.cuts=0)
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-7-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7399581</code></pre>
<p>For this I created a binary variable. I first mutated the data so all Pos are either C for center or A for any other position. I then mutated to create a binarry variable y that is 1 for a Pos of C or 0 for a Pos of A. So 1 for a center and 0 for any other position. I then ran a logistic regression model for y with the interaction of PER and WS. Instead of interpreting the log estimates I converted it. 0.054 is the predicted Pos when PER and WS are both 0. While holding WS constant, 1.099 is the average increase in Pos for every one unit increase in PER and while holding PER constant 1.039 is average increase in Pos for every one unit increase ing WS. I then ran a confusion matrix for the logistic regression. For the accurracy I got 0.817 which means 0.817 of the positions were correctly classified. For the TNR I got 0.995 which means 0.995 of the any other positions were correctly classified. For the TPR I got 0.021 which means 0.021 of the Centers were correctly classified. And for the PPV I got 0.5 which means 0.5 of those classified as centers actually are. The TPR and PPV are very low meaning the model did not do a good job of predicting the center position for a player. I then made an ROC plot and calcultaeed the AUC which is the area under the ROC curve. I got a value of 0.74 which is in essence the probability that a randomly selected player who is a center has a higher predicted probability than a randomly selected player who is any other position. Meaning, on average 74% of Centers will have higher scores than those of any other position.</p>
<pre class="r"><code>library(plotROC)
library(lmtest)
library(glmnet)
NBA3 &lt;- NBA %&gt;% mutate(Pos=ifelse(Pos == &quot;C&quot;, &quot;C&quot;, &quot;A&quot;))
NBA3 &lt;- NBA3 %&gt;% mutate(y=ifelse(Pos==&quot;C&quot;,1,0))
NBA3</code></pre>
<pre><code>## # A tibble: 509 x 7
## Player Pos PER WS BPM VORP y
## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Precious Achiuwa A 13.9 1.2 -4.3 -0.4 0
## 2 Jaylen Adams A -6.5 -0.1 -19.8 -0.1 0
## 3 Steven Adams C 15.2 4 -0.8 0.5 1
## 4 Bam Adebayo C 22.9 8.1 4.8 3.4 1
## 5 LaMarcus Aldridge C 15.7 1.2 -0.6 0.2 1
## 6 Ty-Shon Alexander A -0.3 -0.1 -11 -0.1 0
## 7 Nickeil Alexander-Walker A 12.4 0.7 -1.7 0.1 0
## 8 Grayson Allen A 12.8 2.6 -0.5 0.5 0
## 9 Jarrett Allen C 21 6.2 1.5 1.5 1
## 10 Al-Farouq Aminu A 8.9 0.1 -4 -0.2 0
## # â€¦ with 499 more rows</code></pre>
<pre class="r"><code>fit&lt;-glm(y~PER + WS + BPM + VORP,data=NBA3,family=binomial(link=&quot;logit&quot;))
coeftest(fit)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -9.663226 1.023697 -9.4395 &lt; 2.2e-16 ***
## PER 0.470871 0.060728 7.7538 8.922e-15 ***
## WS 0.452527 0.129608 3.4915 0.0004803 ***
## BPM -0.586531 0.078332 -7.4877 7.008e-14 ***
## VORP -0.750929 0.263113 -2.8540 0.0043171 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit))</code></pre>
<pre><code>## (Intercept) PER WS BPM VORP
## 6.357909e-05 1.601389e+00 1.572280e+00 5.562538e-01
4.719281e-01</code></pre>
<pre class="r"><code>NBA3$prob &lt;- predict(fit,type=&quot;response&quot;)
NBA3$predicted &lt;- ifelse(NBA2$prob&gt;.5,&quot;C&quot;,&quot;A&quot;)
NBA3</code></pre>
<pre><code>## # A tibble: 509 x 9
## Player Pos PER WS BPM VORP y prob predicted
## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
## 1 Precious Achiuwa A 13.9 1.2 -4.3 -0.4 0 0.562 A
## 2 Jaylen Adams A -6.5 -0.1 -19.8 -0.1 0 0.253 A
## 3 Steven Adams C 15.2 4 -0.8 0.5 1 0.354 A
## 4 Bam Adebayo C 22.9 8.1 4.8 3.4 1 0.358 A
## 5 LaMarcus Aldridge C 15.7 1.2 -0.6 0.2 1 0.179 A
## 6 Ty-Shon Alexander A -0.3 -0.1 -11 -0.1 0 0.0348 A
## 7 Nickeil Alexander-Walker A 12.4 0.7 -1.7 0.1 0 0.0701
A
## 8 Grayson Allen A 12.8 2.6 -0.5 0.5 0 0.0730 A
## 9 Jarrett Allen C 21 6.2 1.5 1.5 1 0.736 A
## 10 Al-Farouq Aminu A 8.9 0.1 -4 -0.2 0 0.0506 A
## # â€¦ with 499 more rows</code></pre>
<pre class="r"><code>NBA3$logit&lt;-predict(fit)
NBA3$Pos&lt;-factor(NBA3$Pos,levels=c(&quot;C&quot;,&quot;A&quot;))
table(truth=NBA3$Pos, prediction=NBA3$predicted)%&gt;%addmargins</code></pre>
<pre><code>##      prediction
## truth   A   C Sum
##   C    91   2  93
##   A   414   2 416
##   Sum 505   4 509</code></pre>
<pre class="r"><code>Accuracy &lt;- (2+414)/509 #Accuracy
TNR &lt;- (414/416) #TNR
TPR &lt;- (2/93) #TPR
PPV &lt;- (2/4) #PPV
Accuracy</code></pre>
<pre><code>## [1] 0.8172888</code></pre>
<pre class="r"><code>TNR</code></pre>
<pre><code>## [1] 0.9951923</code></pre>
<pre class="r"><code>TPR</code></pre>
<pre><code>## [1] 0.02150538</code></pre>
<pre class="r"><code>PPV</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="r"><code>ggplot(NBA3,aes(logit, fill=Pos))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ROCplot&lt;-ggplot(NBA3)+geom_roc(aes(d=Pos,m=prob), n.cuts=0)
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-8-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.8008168</code></pre>
<pre class="r"><code>k=10 
data&lt;-NBA3[sample(nrow(NBA3)),] 
folds&lt;-cut(seq(1:nrow(NBA3)),breaks=k,labels=F) 
diags&lt;-NULL
for(i in 1:k){
  train&lt;-data[folds!=i,] 
  test&lt;-data[folds==i,]
  truth&lt;-test$y
  fit&lt;-glm(Pos~PER + WS + BPM + VORP,data=train,family=&quot;binomial&quot;)
  probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean) </code></pre>
<pre><code>##         acc      sens       spec       ppv       auc
## 1 0.1532549 0.7088023 0.03145086 0.1396525 0.2137814</code></pre>
<pre class="r"><code>NBA4 &lt;- NBA3 %&gt;% select(-Player, -y, -prob, -predicted, -logit)
y&lt;-as.matrix(NBA4$Pos) #grab response
x&lt;-model.matrix(Pos~.,data=NBA4)[,-1]
cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      s0
## (Intercept) -5.02651620
## PER          0.21587731
## WS           0.08594338
## BPM         -0.24308247
## VORP         .</code></pre>
<pre class="r"><code>k=10
data &lt;- NBA4 %&gt;% sample_frac 
folds &lt;- ntile(1:nrow(data),n=10) 
diags&lt;-NULL
for(i in 1:k){
train &lt;- data[folds!=i,] #create training set (all but fold i)
test &lt;- data[folds==i,] #create test set (just fold i)
truth &lt;- test$Pos #save truth labels from fold i
fit &lt;- glm(Pos~PER+WS+BPM,
data=train, family=&quot;binomial&quot;)
probs &lt;- predict(fit, newdata=test, type=&quot;response&quot;)
diags&lt;-rbind(diags,class_diag(probs,truth))
}
diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc     sens      spec       ppv      auc
## 1 0.8330588 0.956419 0.2916581 0.8560183 0.792579</code></pre>
<p>I created a fit model this time with all of the variables predicting the binary response variable of Pos. I got a value of 0.817 for the accuracy which means 0.817 of the positions were correctly classified. I got a value of 0.99 for the TNR which means 0.99 of the any other positions were correctly classified. I got a value of 0.021 for the TPR which means 0.021 of the Centers were correctly classified. I got a value of 0.5 for the PPV which means 0.5 of those classified as centers actually are. I also ran an ROC plot and calculated the AUC. I got a value of 0.8 which means on average 80% of Centers will have higher scores than those of any other position. I then performed a 10-fold CV on the same model. Using the 10-fold CV, I got 0.155 for the accuracy which means 0.155 of the positions were correctly classified. I got a value of 0.692 for the sensitivity which means 0.692 of the Centers were correctly classified. I got a valuee of 0.027 for the specificity which means 0.027 of the any other positions were correctly classified. I got a value of 0.14 for the PPV which means 0.14 of those classified as centers actually are. I got a value of 0.207 for the AUC which means on average 20% of Centers will have higher scores than those of any other position. Compared to the in-sample metrics the AUC of the 10-fold CV is much lower and is considered very bad by the rule of thumb. I then performed a LASSO and found that PER, WS, BPM, and VORP are all important predictors of Pos since they were the variables retained. I then performed a 10-fold CV with the variables the LASSO suggested which was all the variables. I got a value of 0.805 for the AUC which is higher than both the in-sample and the original 10-fold CV. And an AUC at 0.805 is considered Good based on the rule of thumb.</p>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with â™¥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
